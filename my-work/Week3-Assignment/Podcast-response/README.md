# Response to Podcast: "Writer's Voice, Automating Inequality w Virginia Eubanks"

## How to technical tools promise to "fair out" the remaining discrimination that exist in social/welfare systems? In how far can they succeed, in which ways do they fail?
Technical tools are used by the U.S government to judge whether a civilian is eligible for social/welfare systems currently. Previously, people need to apply for social/welfare systems' help through in-person contacts with caseworkers, which means that whether a person is eligible for welfare support or not is totally up to the decision of caseworkers--there would be countless factors affecting the fairness of judgment like sexuality, racism or other subjective concepts upon individuals. Technical tools are designed to mitigate the negative effects caused by human factors. By utilizing algorithms, the states hand the right of deciding on machines to guarantee the fairness of judgment. To some extent, it works because the conclusion usually comes out of personal data collection and objective analysis. However, machines also make mistakes sometimes. The inhuman factors of machine and algorithms will also result in the tragedy mentioned by Eubanks.

## Imagine, what could this (following quotes) mean in the widest sense?
> "The state doesn't need a cop to kill a person" and "electronic incarceration"

The state can kill a person simply by throwing a person off the social/welfare systems. It is easy for the state to control or block people's access to a social resource such as housing, food, health insurance. By using technical tools, the people in the U.S are like the prisons online--their information, their lives are monitored by the state and they may even be punished without noticing.

## What do you understand this to mean?
>"systems act as a kind of 'empathy-overwrite'"

The government expects to sort the people who deserve help out by using algorithms systems. The states believe that the decisions made by algorithms are more rational than a human decisions and human empathy towards the poor. The previous decision-makers are convinced by algorithms, thinking that they indeed direct the resources and help to people in need.

## China is much more advanced and expansive when it comes to applying technical solutions to societal processes or instant challenges (recent example). Try to point example cases in China that are in accordance or in opposition to the problematics discussed in the podcast. Perhaps you can think of
>"technical systems not well thought-through about what their impace on human beings is"

Credits systems and facial recognition technology are widely used in China. The combination of these two algorithms systems is a powerful tool for social maintenance and crime prediction. However, it will still affect people's life. I saw a true example on Zhihu(Chinese Quora). A person who used to be an addict to drugs has drug history on a social credits system. One day, he went to the office by taking the subway. As he got out of the subway station, he was arrested by police because his face was recognized by the facial recognition camera installed in the subway station and his drug history was quickly extracted by the algorithms. He was brought to the police station with the excuse of reusing drugs. In this case, this person did not reuse drug but his life was affected under the "bad record". "technical systems not well thought-through about what their impact on human beings is". We still need to rethink how technologies impact our life, not just positively, but also negatively even just for a small group of people 
